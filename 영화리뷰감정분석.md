```python
import pandas as pd
import numpy as np
import warnings
import os
import matplotlib.pyplot as plt
import seaborn as sns

warnings.filterwarnings('ignore')
SEED=33
```


```python
DATA='./data'
```


```python
train=pd.read_csv(os.path.join(DATA, 'train.tsv'), delimiter='\t')
test=pd.read_csv(os.path.join(DATA, 'test.tsv'),delimiter='\t')
```


```python
unlabeled_train=pd.read_csv(os.path.join(DATA, 'unlabeled-train.tsv'), delimiter='\t', error_bad_lines=False )##에러때문에
```

    b'Skipping line 43043: expected 2 fields, saw 3\n'
    

train파일-

총 25000개 파일이 있고 칼럼이 3개 
sentiment 는 1이면 긍정이고 0이면 부정 

test파일 -

25000개 파일이지만 칼럼이 2개임, sentiment는 내가 만들어야 함 

unlabled 파일 - 


총 49998 (2개는 에러) , 레이블 값은 없고 리뷰만 있다. 


```python
print(train.shape)  ##1이면 긍정 0이면 부정 
train.head() 
```

    (25000, 3)
    




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>sentiment</th>
      <th>review</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>5814_8</td>
      <td>1</td>
      <td>With all this stuff going down at the moment w...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2381_9</td>
      <td>1</td>
      <td>\The Classic War of the Worlds\" by Timothy Hi...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>7759_3</td>
      <td>0</td>
      <td>The film starts with a manager (Nicholas Bell)...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3630_4</td>
      <td>0</td>
      <td>It must be assumed that those who praised this...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>9495_8</td>
      <td>1</td>
      <td>Superbly trashy and wondrously unpretentious 8...</td>
    </tr>
  </tbody>
</table>
</div>




```python
print(test.shape)
test.head() 
```

    (25000, 2)
    




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>review</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>12311_10</td>
      <td>Naturally in a film who's main themes are of m...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>8348_2</td>
      <td>This movie is a disaster within a disaster fil...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>5828_4</td>
      <td>All in all, this is a movie for kids. We saw i...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>7186_2</td>
      <td>Afraid of the Dark left me with the impression...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>12128_7</td>
      <td>A very accurate depiction of small time mob li...</td>
    </tr>
  </tbody>
</table>
</div>




```python
print(unlabeled_train.shape) ##unlabeled_train 데이터-> 리뷰만 있음 
unlabeled_train.head()
```

    (49998, 2)
    




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>review</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>9999_0</td>
      <td>Watching Time Chasers, it obvious that it was ...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>45057_0</td>
      <td>I saw this film about 20 years ago and remembe...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>15561_0</td>
      <td>Minor Spoilers&lt;br /&gt;&lt;br /&gt;In New York, Joan Ba...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>7161_0</td>
      <td>I went to see this film with a great deal of e...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>43971_0</td>
      <td>Yes, I agree with everyone on this site this m...</td>
    </tr>
  </tbody>
</table>
</div>



beutiful Soup을 이용하여 태그를 제거,


stopword을 이용하여 불용어 (조사 - 은는이가,  자주쓰이지만 의미없는 단어 


```python
from bs4 import BeautifulSoup 
from nltk.corpus import stopwords 
```


```python
sample=train['review'][0]
sample
```




    "With all this stuff going down at the moment with MJ i've started listening to his music, watching the odd documentary here and there, watched The Wiz and watched Moonwalker again. Maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent. Moonwalker is part biography, part feature film which i remember going to see at the cinema when it was originally released. Some of it has subtle messages about MJ's feeling towards the press and also the obvious message of drugs are bad m'kay.<br /><br />Visually impressive but of course this is all about Michael Jackson so unless you remotely like MJ in anyway then you are going to hate this and find it boring. Some may call MJ an egotist for consenting to the making of this movie BUT MJ and most of his fans would say that he made it for the fans which if true is really nice of him.<br /><br />The actual feature film bit when it finally starts is only on for 20 minutes or so excluding the Smooth Criminal sequence and Joe Pesci is convincing as a psychopathic all powerful drug lord. Why he wants MJ dead so bad is beyond me. Because MJ overheard his plans? Nah, Joe Pesci's character ranted that he wanted people to know it is he who is supplying drugs etc so i dunno, maybe he just hates MJ's music.<br /><br />Lots of cool things in this like MJ turning into a car and a robot and the whole Speed Demon sequence. Also, the director must have had the patience of a saint when it came to filming the kiddy Bad sequence as usually directors hate working with one kid let alone a whole bunch of them performing a complex dance scene.<br /><br />Bottom line, this movie is for people who like MJ on one level or another (which i think is most people). If not, then stay away. It does try and give off a wholesome message and ironically MJ's bestest buddy in this movie is a girl! Michael Jackson is truly one of the most talented people ever to grace this planet but is he guilty? Well, with all the attention i've gave this subject....hmmm well i don't know because people can be different behind closed doors, i know this for a fact. He is either an extremely nice but stupid guy or one of the most sickest liars. I hope he is not the latter."



html 태그제거 
 
 soup=BeautifulSoup(sample, 'html.parser')
 soup.text 
 


```python
 soup=BeautifulSoup(sample, 'html.parser')
 soup.text 

```




    "With all this stuff going down at the moment with MJ i've started listening to his music, watching the odd documentary here and there, watched The Wiz and watched Moonwalker again. Maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent. Moonwalker is part biography, part feature film which i remember going to see at the cinema when it was originally released. Some of it has subtle messages about MJ's feeling towards the press and also the obvious message of drugs are bad m'kay.Visually impressive but of course this is all about Michael Jackson so unless you remotely like MJ in anyway then you are going to hate this and find it boring. Some may call MJ an egotist for consenting to the making of this movie BUT MJ and most of his fans would say that he made it for the fans which if true is really nice of him.The actual feature film bit when it finally starts is only on for 20 minutes or so excluding the Smooth Criminal sequence and Joe Pesci is convincing as a psychopathic all powerful drug lord. Why he wants MJ dead so bad is beyond me. Because MJ overheard his plans? Nah, Joe Pesci's character ranted that he wanted people to know it is he who is supplying drugs etc so i dunno, maybe he just hates MJ's music.Lots of cool things in this like MJ turning into a car and a robot and the whole Speed Demon sequence. Also, the director must have had the patience of a saint when it came to filming the kiddy Bad sequence as usually directors hate working with one kid let alone a whole bunch of them performing a complex dance scene.Bottom line, this movie is for people who like MJ on one level or another (which i think is most people). If not, then stay away. It does try and give off a wholesome message and ironically MJ's bestest buddy in this movie is a girl! Michael Jackson is truly one of the most talented people ever to grace this planet but is he guilty? Well, with all the attention i've gave this subject....hmmm well i don't know because people can be different behind closed doors, i know this for a fact. He is either an extremely nice but stupid guy or one of the most sickest liars. I hope he is not the latter."




```python
#특수기호 제거
import re
```


```python
cleaned=re.sub('[^a-zA-Z]',' ',soup.text)
#a-z ~ A-Z 가 아닌 문자를 지우고 공백으로 채워준다 
```


```python
cleaned
```




    'With all this stuff going down at the moment with MJ i ve started listening to his music  watching the odd documentary here and there  watched The Wiz and watched Moonwalker again  Maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent  Moonwalker is part biography  part feature film which i remember going to see at the cinema when it was originally released  Some of it has subtle messages about MJ s feeling towards the press and also the obvious message of drugs are bad m kay Visually impressive but of course this is all about Michael Jackson so unless you remotely like MJ in anyway then you are going to hate this and find it boring  Some may call MJ an egotist for consenting to the making of this movie BUT MJ and most of his fans would say that he made it for the fans which if true is really nice of him The actual feature film bit when it finally starts is only on for    minutes or so excluding the Smooth Criminal sequence and Joe Pesci is convincing as a psychopathic all powerful drug lord  Why he wants MJ dead so bad is beyond me  Because MJ overheard his plans  Nah  Joe Pesci s character ranted that he wanted people to know it is he who is supplying drugs etc so i dunno  maybe he just hates MJ s music Lots of cool things in this like MJ turning into a car and a robot and the whole Speed Demon sequence  Also  the director must have had the patience of a saint when it came to filming the kiddy Bad sequence as usually directors hate working with one kid let alone a whole bunch of them performing a complex dance scene Bottom line  this movie is for people who like MJ on one level or another  which i think is most people   If not  then stay away  It does try and give off a wholesome message and ironically MJ s bestest buddy in this movie is a girl  Michael Jackson is truly one of the most talented people ever to grace this planet but is he guilty  Well  with all the attention i ve gave this subject    hmmm well i don t know because people can be different behind closed doors  i know this for a fact  He is either an extremely nice but stupid guy or one of the most sickest liars  I hope he is not the latter '



모두 소문자로 바꾼다- With 랑 with는 다르게 인식하기 때문에 
순수하게 단어만 보기 위해서 


```python
cleaned.lower()
```




    'with all this stuff going down at the moment with mj i ve started listening to his music  watching the odd documentary here and there  watched the wiz and watched moonwalker again  maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent  moonwalker is part biography  part feature film which i remember going to see at the cinema when it was originally released  some of it has subtle messages about mj s feeling towards the press and also the obvious message of drugs are bad m kay visually impressive but of course this is all about michael jackson so unless you remotely like mj in anyway then you are going to hate this and find it boring  some may call mj an egotist for consenting to the making of this movie but mj and most of his fans would say that he made it for the fans which if true is really nice of him the actual feature film bit when it finally starts is only on for    minutes or so excluding the smooth criminal sequence and joe pesci is convincing as a psychopathic all powerful drug lord  why he wants mj dead so bad is beyond me  because mj overheard his plans  nah  joe pesci s character ranted that he wanted people to know it is he who is supplying drugs etc so i dunno  maybe he just hates mj s music lots of cool things in this like mj turning into a car and a robot and the whole speed demon sequence  also  the director must have had the patience of a saint when it came to filming the kiddy bad sequence as usually directors hate working with one kid let alone a whole bunch of them performing a complex dance scene bottom line  this movie is for people who like mj on one level or another  which i think is most people   if not  then stay away  it does try and give off a wholesome message and ironically mj s bestest buddy in this movie is a girl  michael jackson is truly one of the most talented people ever to grace this planet but is he guilty  well  with all the attention i ve gave this subject    hmmm well i don t know because people can be different behind closed doors  i know this for a fact  he is either an extremely nice but stupid guy or one of the most sickest liars  i hope he is not the latter '




```python
cleaned.lower().split()[:10] ##단어로 쪼개기 
```




    ['with',
     'all',
     'this',
     'stuff',
     'going',
     'down',
     'at',
     'the',
     'moment',
     'with']




```python
eng_stopwords=stopwords.words('english')
```


```python
##불용어제거하는 함수 (지금까지 했던 것을 함수로 만듬)
def preprocessing(sentence):
    soup=BeautifulSoup(sentence,'html.parser')
    cleaned=re.sub('[^a-zA-Z]', ' ',soup.text )
    cleaned.lower()
    cleaned=[word for word in cleaned.split() if word not in eng_stopwords]
    return' '.join(cleaned) ##문장처럼 나오도록 
```


```python
preprocessing(sample)

```




    'With stuff going moment MJ started listening music watching odd documentary watched The Wiz watched Moonwalker Maybe want get certain insight guy thought really cool eighties maybe make mind whether guilty innocent Moonwalker part biography part feature film remember going see cinema originally released Some subtle messages MJ feeling towards press also obvious message drugs bad kay Visually impressive course Michael Jackson unless remotely like MJ anyway going hate find boring Some may call MJ egotist consenting making movie BUT MJ fans would say made fans true really nice The actual feature film bit finally starts minutes excluding Smooth Criminal sequence Joe Pesci convincing psychopathic powerful drug lord Why wants MJ dead bad beyond Because MJ overheard plans Nah Joe Pesci character ranted wanted people know supplying drugs etc dunno maybe hates MJ music Lots cool things like MJ turning car robot whole Speed Demon sequence Also director must patience saint came filming kiddy Bad sequence usually directors hate working one kid let alone whole bunch performing complex dance scene Bottom line movie people like MJ one level another think people If stay away It try give wholesome message ironically MJ bestest buddy movie girl Michael Jackson truly one talented people ever grace planet guilty Well attention gave subject hmmm well know people different behind closed doors know fact He either extremely nice stupid guy one sickest liars I hope latter'




```python
s=['i' , 'am' ,'a','boy']
```


```python
for word in s:
    if word in eng_stopwords:
        print(word)
```

    i
    am
    a
    


```python
preprocessing(sample)
```




    'With stuff going moment MJ started listening music watching odd documentary watched The Wiz watched Moonwalker Maybe want get certain insight guy thought really cool eighties maybe make mind whether guilty innocent Moonwalker part biography part feature film remember going see cinema originally released Some subtle messages MJ feeling towards press also obvious message drugs bad kay Visually impressive course Michael Jackson unless remotely like MJ anyway going hate find boring Some may call MJ egotist consenting making movie BUT MJ fans would say made fans true really nice The actual feature film bit finally starts minutes excluding Smooth Criminal sequence Joe Pesci convincing psychopathic powerful drug lord Why wants MJ dead bad beyond Because MJ overheard plans Nah Joe Pesci character ranted wanted people know supplying drugs etc dunno maybe hates MJ music Lots cool things like MJ turning car robot whole Speed Demon sequence Also director must patience saint came filming kiddy Bad sequence usually directors hate working one kid let alone whole bunch performing complex dance scene Bottom line movie people like MJ one level another think people If stay away It try give wholesome message ironically MJ bestest buddy movie girl Michael Jackson truly one talented people ever grace planet guilty Well attention gave subject hmmm well know people different behind closed doors know fact He either extremely nice stupid guy one sickest liars I hope latter'




```python
for word in sample.lower().split():
    if word in eng_stopwords:
        print(word)
```

    with
    all
    this
    down
    at
    the
    with
    to
    his
    the
    here
    and
    the
    and
    i
    just
    to
    a
    into
    this
    who
    i
    was
    in
    the
    just
    to
    up
    my
    he
    is
    or
    is
    which
    i
    to
    at
    the
    when
    it
    was
    some
    of
    it
    has
    about
    the
    and
    the
    of
    are
    but
    of
    this
    is
    all
    about
    so
    you
    in
    then
    you
    are
    to
    this
    and
    it
    some
    an
    for
    to
    the
    of
    this
    but
    and
    most
    of
    his
    that
    he
    it
    for
    the
    which
    if
    is
    of
    when
    it
    is
    only
    on
    for
    or
    so
    the
    and
    is
    as
    a
    all
    why
    he
    so
    is
    because
    his
    that
    he
    to
    it
    is
    he
    who
    is
    so
    i
    he
    just
    of
    in
    this
    into
    a
    and
    a
    and
    the
    the
    have
    had
    the
    of
    a
    when
    it
    to
    the
    as
    with
    a
    of
    them
    a
    this
    is
    for
    who
    on
    or
    i
    is
    most
    if
    then
    it
    does
    and
    off
    a
    and
    in
    this
    is
    a
    is
    of
    the
    most
    to
    this
    but
    is
    he
    with
    all
    the
    this
    i
    don't
    because
    can
    be
    i
    this
    for
    a
    he
    is
    an
    but
    or
    of
    the
    most
    i
    he
    is
    not
    the
    


```python
all_review = pd.concat([train['review'], 
        unlabeled_train['review'], test['review']])
##all_review 변수에  리뷰들을 모음 
all_review.head()
```




    0    With all this stuff going down at the moment w...
    1    \The Classic War of the Worlds\" by Timothy Hi...
    2    The film starts with a manager (Nicholas Bell)...
    3    It must be assumed that those who praised this...
    4    Superbly trashy and wondrously unpretentious 8...
    Name: review, dtype: object




```python
all_review_clean= all_review.apply(preprocessing)

```


```python
all_review_clean.head()
```




    0    With stuff going moment MJ started listening m...
    1    The Classic War Worlds Timothy Hines entertain...
    2    The film starts manager Nicholas Bell giving w...
    3    It must assumed praised film greatest filmed o...
    4    Superbly trashy wondrously unpretentious explo...
    Name: review, dtype: object




```python
from sklearn.feature_extraction.text import CountVectorizer ##단어의 빈도수를 셈 
```


```python
cv=CountVectorizer(analyzer="word", max_features=5000)  ##빈도수가 가장높은 5000개만 가져옴 
```


```python
all_review_cv=cv.fit_transform(all_review_clean)
```


```python
all_review_cv.shape 
```




    (99998, 5000)




```python
all_review_cv.toarray()[0]  ##1번째를 가져와서 빈도수를 보는데, 5000개가 너무많아서 안보였음 
```




    array([0, 0, 0, ..., 0, 0, 0], dtype=int64)




```python
##묶어서 전처리 완료된 데이터를 train과, test데이터로 다시 쪼갬

train_sentences =all_review_cv[:len(train)]
test_sentences=all_review_cv[-len(test):] 
```


```python
train_sentences.shape, test_sentences.shape
```




    ((25000, 5000), (25000, 5000))




```python
train_labels=train['sentiment']
```


```python
train_labels.shape
```




    (25000,)




```python
from sklearn.ensemble import RandomForestClassifier
```


```python
rfc= RandomForestClassifier(n_estimators=1000,    
                            max_depth=8, n_jobs=-1)

##n_jobs=-1 모든코어를 사용해서 학습
```


```python
rfc.fit(train_sentences, train_labels)
```




    RandomForestClassifier(max_depth=8, n_estimators=1000, n_jobs=-1)




```python
prediction=rfc.predict(test_sentences)
```


```python
prediction.shape
```




    (25000,)




```python
prediction[:10]
```




    array([1, 0, 1, 1, 1, 0, 0, 1, 0, 0], dtype=int64)




```python
submission=pd.read_csv(os.path.join(DATA, 'sampleSubmission.csv'))

```


```python
submission.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>sentiment</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>12311_10</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>8348_2</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>5828_4</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>7186_2</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>12128_7</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>




```python
submission['sentiment'] = prediction
```


```python
submission['sentiment'].value_counts()
##긍정과 부정이 몇개인지 
```




    1    13770
    0    11230
    Name: sentiment, dtype: int64




```python
submission['sentiment'] = submission['sentiment'].astype('int')
```


```python
submission.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>sentiment</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>12311_10</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>8348_2</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>5828_4</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>7186_2</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>12128_7</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>




```python
import datetime
```


```python
timestring = datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S')
```


```python
filename = 'C:data/submission-{timestring}.csv'
```


```python
filename
```


```python
submission.to_csv(filename, index=False)
```


```python
from nltk.stem import WordNetLemmatizer
```


```python
lemmatizer = WordNetLemmatizer()
```


```python
print(lemmatizer.lemmatize('runs'))
print(lemmatizer.lemmatize('ran'))
print(lemmatizer.lemmatize('run'))

print(lemmatizer.lemmatize('apple'))
print(lemmatizer.lemmatize('apples'))
```


```python
def process_lemma(sentence):        
    return [lemmatizer.lemmatize(word, 'v') for word in sentence]
```


```python
def preprocessing(sentence):
    soup = BeautifulSoup(sentence, 'html.parser')
    cleaned = re.sub('[^a-zA-Z]', ' ', soup.text)
    cleaned = cleaned.lower()
    cleaned = [word for word in cleaned.split() if word not in eng_stopwords]
    cleaned = process_lemma(cleaned)
    return ' '.join(cleaned)
```


```python
all_review = pd.concat([train['review'], unlabeled_train['review'], test['review']])
```


```python
all_review_clean = all_review.apply(preprocessing)
```


```python
all_review_clean.head()
```




    0    stuff go moment mj start listen music watch od...
    1    classic war worlds timothy hines entertain fil...
    2    film start manager nicholas bell give welcome ...
    3    must assume praise film greatest film opera ev...
    4    superbly trashy wondrously unpretentious explo...
    Name: review, dtype: object




```python
from tensorflow.keras.preprocessing.text import Tokenizer
```


```python
tokenizer = Tokenizer(oov_token='<OOV>')
```


```python
tokenizer.fit_on_texts(all_review_clean)
```


```python
len(tokenizer.word_index)
```




    126309




```python
for i, word in enumerate(tokenizer.word_index):
    if i > 20:
        break
    print(word, tokenizer.word_index[word])
```

    <OOV> 1
    film 2
    movie 3
    one 4
    make 5
    like 6
    see 7
    get 8
    time 9
    good 10
    character 11
    go 12
    watch 13
    even 14
    would 15
    think 16
    story 17
    really 18
    well 19
    show 20
    look 21
    


```python
train_sentences = all_review_clean[:len(train)]
test_sentences = all_review_clean[-len(test):]
```


```python
train_sentences.shape, test_sentences.shape
```




    ((25000,), (25000,))




```python
train_sequences = tokenizer.texts_to_sequences(train_sentences)
test_sequences = tokenizer.texts_to_sequences(test_sentences)
```


```python
train_sequences[0]
```




    [397,
     12,
     463,
     11594,
     83,
     930,
     127,
     13,
     895,
     507,
     13,
     21106,
     13,
     19435,
     179,
     46,
     8,
     639,
     2250,
     66,
     16,
     18,
     469,
     3272,
     179,
     5,
     188,
     643,
     2110,
     1155,
     19435,
     58,
     4431,
     58,
     258,
     2,
     240,
     12,
     7,
     349,
     1643,
     255,
     1145,
     550,
     11594,
     59,
     773,
     2039,
     29,
     470,
     550,
     593,
     26,
     4231,
     1924,
     1032,
     175,
     420,
     1453,
     782,
     2209,
     6,
     11594,
     459,
     12,
     613,
     37,
     170,
     116,
     146,
     11594,
     34889,
     9295,
     5,
     3,
     11594,
     109,
     15,
     25,
     5,
     109,
     198,
     18,
     253,
     727,
     258,
     2,
     114,
     339,
     83,
     141,
     7788,
     3475,
     1502,
     311,
     781,
     6908,
     526,
     9123,
     785,
     593,
     1370,
     46,
     11594,
     242,
     26,
     558,
     11594,
     9786,
     505,
     12451,
     781,
     6908,
     11,
     3763,
     46,
     27,
     24,
     2666,
     593,
     413,
     8743,
     179,
     724,
     11594,
     127,
     64,
     469,
     94,
     6,
     11594,
     90,
     419,
     1904,
     130,
     1523,
     2147,
     311,
     29,
     68,
     113,
     3929,
     3388,
     36,
     2,
     22088,
     26,
     311,
     516,
     843,
     613,
     43,
     4,
     129,
     152,
     518,
     130,
     630,
     890,
     1120,
     423,
     55,
     1131,
     107,
     3,
     27,
     6,
     11594,
     4,
     410,
     76,
     16,
     27,
     407,
     155,
     49,
     32,
     6493,
     550,
     3286,
     11594,
     37211,
     1734,
     3,
     150,
     420,
     1453,
     288,
     4,
     881,
     27,
     52,
     1259,
     1190,
     2110,
     19,
     552,
     32,
     561,
     6075,
     19,
     24,
     27,
     177,
     425,
     321,
     3255,
     24,
     102,
     267,
     462,
     253,
     286,
     66,
     4,
     16683,
     17233,
     331,
     1410]




```python
from tensorflow.keras.preprocessing.sequence import pad_sequences
```


```python
MAX_LENGTH = 150
```


```python
train_padded = pad_sequences(train_sequences, maxlen=MAX_LENGTH, truncating='post', padding='post')
test_padded = pad_sequences(test_sequences, maxlen=MAX_LENGTH, truncating='post', padding='post')
```


```python
train_padded.shape, test_padded.shape
```




    ((25000, 150), (25000, 150))




```python
train_labels = train['sentiment']
```


```python
from sklearn.model_selection import train_test_split
```


```python
x_train, x_valid, y_train, y_valid = train_test_split(train_padded, train_labels, stratify=train_labels, test_size=0.1, random_state=SEED)
```


```python
from gensim.models import KeyedVectors
```


```python
word2vec = KeyedVectors.load_word2vec_format('C:/data/GoogleNews-vectors-negative300.bin', binary=True)
```


    ---------------------------------------------------------------------------

    FileNotFoundError                         Traceback (most recent call last)

    <ipython-input-85-55d7a369781b> in <module>
    ----> 1 word2vec = KeyedVectors.load_word2vec_format('C:/data/GoogleNews-vectors-negative300.bin', binary=True)
    

    ~\anaconda3\lib\site-packages\gensim\models\keyedvectors.py in load_word2vec_format(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header)
       1627 
       1628         """
    -> 1629         return _load_word2vec_format(
       1630             cls, fname, fvocab=fvocab, binary=binary, encoding=encoding, unicode_errors=unicode_errors,
       1631             limit=limit, datatype=datatype, no_header=no_header,
    

    ~\anaconda3\lib\site-packages\gensim\models\keyedvectors.py in _load_word2vec_format(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header, binary_chunk_size)
       1953 
       1954     logger.info("loading projection weights from %s", fname)
    -> 1955     with utils.open(fname, 'rb') as fin:
       1956         if no_header:
       1957             # deduce both vocab_size & vector_size from 1st pass over file
    

    ~\anaconda3\lib\site-packages\smart_open\smart_open_lib.py in open(uri, mode, buffering, encoding, errors, newline, closefd, opener, ignore_ext, compression, transport_params)
        186         transport_params = {}
        187 
    --> 188     fobj = _shortcut_open(
        189         uri,
        190         mode,
    

    ~\anaconda3\lib\site-packages\smart_open\smart_open_lib.py in _shortcut_open(uri, mode, compression, buffering, encoding, errors, newline)
        359         open_kwargs['errors'] = errors
        360 
    --> 361     return _builtin_open(local_path, mode, buffering=buffering, **open_kwargs)
        362 
        363 
    

    FileNotFoundError: [Errno 2] No such file or directory: 'C:/data/GoogleNews-vectors-negative300.bin'



```python
VOCAB_SIZE = len(tokenizer.word_index) + 1
EMBEDDING_DIM = 300

embedding_matrix = np.zeros((VOCAB_SIZE, EMBEDDING_DIM))
```


```python
for word, idx in tokenizer.word_index.items():
    embedding_vector = word2vec[word] if word in word2vec else None
    if embedding_vector is not None:
        embedding_matrix[idx] = embedding_vector
```


    ---------------------------------------------------------------------------

    NameError                                 Traceback (most recent call last)

    <ipython-input-87-ee461c87b487> in <module>
          1 for word, idx in tokenizer.word_index.items():
    ----> 2     embedding_vector = word2vec[word] if word in word2vec else None
          3     if embedding_vector is not None:
          4         embedding_matrix[idx] = embedding_vector
    

    NameError: name 'word2vec' is not defined



```python
embedding_matrix.shape
```




    (126310, 300)




```python
tokenizer.word_index
```




    {'<OOV>': 1,
     'film': 2,
     'movie': 3,
     'one': 4,
     'make': 5,
     'like': 6,
     'see': 7,
     'get': 8,
     'time': 9,
     'good': 10,
     'character': 11,
     'go': 12,
     'watch': 13,
     'even': 14,
     'would': 15,
     'think': 16,
     'story': 17,
     'really': 18,
     'well': 19,
     'show': 20,
     'look': 21,
     'much': 22,
     'end': 23,
     'know': 24,
     'say': 25,
     'bad': 26,
     'people': 27,
     'great': 28,
     'also': 29,
     'first': 30,
     'take': 31,
     'give': 32,
     'act': 33,
     'play': 34,
     'love': 35,
     'come': 36,
     'find': 37,
     'way': 38,
     'could': 39,
     'movies': 40,
     'seem': 41,
     'plot': 42,
     'work': 43,
     'two': 44,
     'many': 45,
     'want': 46,
     'never': 47,
     'life': 48,
     'try': 49,
     'best': 50,
     'little': 51,
     'ever': 52,
     'man': 53,
     'better': 54,
     'scene': 55,
     'still': 56,
     'scenes': 57,
     'part': 58,
     'feel': 59,
     'something': 60,
     'use': 61,
     'back': 62,
     'interest': 63,
     'lot': 64,
     'real': 65,
     'guy': 66,
     'thing': 67,
     'director': 68,
     'actors': 69,
     'funny': 70,
     'though': 71,
     'cast': 72,
     'star': 73,
     'years': 74,
     'live': 75,
     'another': 76,
     'old': 77,
     'leave': 78,
     'actually': 79,
     'nothing': 80,
     'tell': 81,
     'new': 82,
     'start': 83,
     'write': 84,
     'point': 85,
     'every': 86,
     'set': 87,
     'action': 88,
     'become': 89,
     'turn': 90,
     'world': 91,
     'kill': 92,
     'us': 93,
     'things': 94,
     'horror': 95,
     'happen': 96,
     'quite': 97,
     'pretty': 98,
     'around': 99,
     'long': 100,
     'young': 101,
     'fact': 102,
     'mean': 103,
     'however': 104,
     'enough': 105,
     'right': 106,
     'line': 107,
     'big': 108,
     'fan': 109,
     'keep': 110,
     'comedy': 111,
     'script': 112,
     'must': 113,
     'bite': 114,
     'series': 115,
     'may': 116,
     'enjoy': 117,
     'need': 118,
     'without': 119,
     'begin': 120,
     'role': 121,
     'original': 122,
     'last': 123,
     'saw': 124,
     'shoot': 125,
     'always': 126,
     'music': 127,
     'put': 128,
     'kid': 129,
     'whole': 130,
     'almost': 131,
     'lead': 132,
     'place': 133,
     'least': 134,
     'laugh': 135,
     'do': 136,
     'believe': 137,
     'run': 138,
     'far': 139,
     'effect': 140,
     'minutes': 141,
     'since': 142,
     'reason': 143,
     'family': 144,
     'might': 145,
     'call': 146,
     'name': 147,
     'screen': 148,
     'anything': 149,
     'girl': 150,
     'performance': 151,
     'let': 152,
     'yet': 153,
     'probably': 154,
     'away': 155,
     'tv': 156,
     'book': 157,
     'kind': 158,
     'woman': 159,
     'fun': 160,
     'hard': 161,
     'help': 162,
     'rather': 163,
     'worst': 164,
     'day': 165,
     'anyone': 166,
     'sure': 167,
     'read': 168,
     'war': 169,
     'bore': 170,
     'expect': 171,
     'especially': 172,
     'sense': 173,
     'although': 174,
     'course': 175,
     'bring': 176,
     'different': 177,
     'dvd': 178,
     'maybe': 179,
     'worth': 180,
     'three': 181,
     'job': 182,
     'everything': 183,
     'move': 184,
     'american': 185,
     'face': 186,
     'lose': 187,
     'mind': 188,
     'actor': 189,
     'second': 190,
     'main': 191,
     'money': 192,
     'direct': 193,
     'someone': 194,
     'together': 195,
     'everyone': 196,
     'year': 197,
     'true': 198,
     'john': 199,
     'instead': 200,
     'sound': 201,
     'understand': 202,
     'high': 203,
     'black': 204,
     'waste': 205,
     'recommend': 206,
     'follow': 207,
     'view': 208,
     'special': 209,
     'fight': 210,
     'talk': 211,
     'audience': 212,
     'night': 213,
     'later': 214,
     'miss': 215,
     'fall': 216,
     'head': 217,
     'eye': 218,
     'hear': 219,
     'die': 220,
     'half': 221,
     'house': 222,
     'wife': 223,
     'hand': 224,
     'open': 225,
     'change': 226,
     'death': 227,
     'surprise': 228,
     'idea': 229,
     'beautiful': 230,
     'excellent': 231,
     'short': 232,
     'budget': 233,
     'father': 234,
     'include': 235,
     'else': 236,
     'couple': 237,
     'men': 238,
     'simply': 239,
     'remember': 240,
     'top': 241,
     'dead': 242,
     'version': 243,
     'piece': 244,
     'appear': 245,
     'home': 246,
     'entertain': 247,
     'completely': 248,
     'attempt': 249,
     'poor': 250,
     'picture': 251,
     'involve': 252,
     'nice': 253,
     'care': 254,
     'release': 255,
     'less': 256,
     'along': 257,
     'feature': 258,
     'hollywood': 259,
     'sex': 260,
     'word': 261,
     'meet': 262,
     'suppose': 263,
     'women': 264,
     'add': 265,
     'wrong': 266,
     'either': 267,
     'title': 268,
     'low': 269,
     'school': 270,
     'performances': 271,
     'friends': 272,
     'camera': 273,
     'lack': 274,
     'game': 275,
     'murder': 276,
     'next': 277,
     'rat': 278,
     'production': 279,
     'full': 280,
     'mother': 281,
     'style': 282,
     'decide': 283,
     'classic': 284,
     'rest': 285,
     'stupid': 286,
     'save': 287,
     'truly': 288,
     'awful': 289,
     'video': 290,
     'flick': 291,
     'base': 292,
     'case': 293,
     'perhaps': 294,
     'moments': 295,
     'review': 296,
     'create': 297,
     'terrible': 298,
     'sort': 299,
     'light': 300,
     'age': 301,
     'wonder': 302,
     'stop': 303,
     'others': 304,
     'small': 305,
     'force': 306,
     'boy': 307,
     'joke': 308,
     'person': 309,
     'wonderful': 310,
     'sequence': 311,
     'stand': 312,
     'guess': 313,
     'experience': 314,
     'perfect': 315,
     'definitely': 316,
     'sit': 317,
     'human': 318,
     'often': 319,
     'comment': 320,
     'close': 321,
     'dialogue': 322,
     'side': 323,
     'early': 324,
     'break': 325,
     'children': 326,
     'mention': 327,
     'cut': 328,
     'episode': 329,
     'yes': 330,
     'hope': 331,
     'friend': 332,
     'certainly': 333,
     'consider': 334,
     'hold': 335,
     'matter': 336,
     'oh': 337,
     'absolutely': 338,
     'finally': 339,
     'amaze': 340,
     'disappoint': 341,
     'several': 342,
     'type': 343,
     'buy': 344,
     'hit': 345,
     'drama': 346,
     'worse': 347,
     'problem': 348,
     'cinema': 349,
     'ask': 350,
     'overall': 351,
     'fail': 352,
     'white': 353,
     'entire': 354,
     'spend': 355,
     'humor': 356,
     'felt': 357,
     'direction': 358,
     'deal': 359,
     'speak': 360,
     'voice': 361,
     'son': 362,
     'dark': 363,
     'learn': 364,
     'evil': 365,
     'wait': 366,
     'totally': 367,
     'mr': 368,
     'despite': 369,
     'forget': 370,
     'final': 371,
     'killer': 372,
     'b': 373,
     'throughout': 374,
     'power': 375,
     'unfortunately': 376,
     'already': 377,
     'history': 378,
     'able': 379,
     'manage': 380,
     'group': 381,
     'support': 382,
     'days': 383,
     'twist': 384,
     'throw': 385,
     'walk': 386,
     'town': 387,
     'number': 388,
     'genre': 389,
     'fine': 390,
     'present': 391,
     'pay': 392,
     'quality': 393,
     'heart': 394,
     'rent': 395,
     'horrible': 396,
     'stuff': 397,
     'credit': 398,
     'today': 399,
     'example': 400,
     'touch': 401,
     'city': 402,
     'question': 403,
     'portray': 404,
     'score': 405,
     'wish': 406,
     'stay': 407,
     'child': 408,
     'theme': 409,
     'level': 410,
     'past': 411,
     'realize': 412,
     'etc': 413,
     'viewer': 414,
     'drive': 415,
     'please': 416,
     'deserve': 417,
     'build': 418,
     'car': 419,
     'michael': 420,
     'blood': 421,
     'catch': 422,
     'dance': 423,
     'body': 424,
     'behind': 425,
     'favorite': 426,
     'daughter': 427,
     'soon': 428,
     'art': 429,
     'brilliant': 430,
     'decent': 431,
     'return': 432,
     'girls': 433,
     'annoy': 434,
     'self': 435,
     'order': 436,
     'obviously': 437,
     'pace': 438,
     'sometimes': 439,
     'actress': 440,
     'god': 441,
     'late': 442,
     'hour': 443,
     'chance': 444,
     'slow': 445,
     'career': 446,
     'except': 447,
     'violence': 448,
     'husband': 449,
     'grow': 450,
     'writer': 451,
     'edit': 452,
     'complete': 453,
     'highly': 454,
     'hero': 455,
     'stories': 456,
     'cop': 457,
     'figure': 458,
     'anyway': 459,
     'state': 460,
     'police': 461,
     'extremely': 462,
     'moment': 463,
     'jam': 464,
     'pick': 465,
     'hell': 466,
     'roles': 467,
     'result': 468,
     'cool': 469,
     'obvious': 470,
     'ok': 471,
     'offer': 472,
     'david': 473,
     'strong': 474,
     'room': 475,
     'dream': 476,
     'robert': 477,
     'cause': 478,
     'hilarious': 479,
     'deliver': 480,
     'gore': 481,
     'brother': 482,
     'simple': 483,
     'value': 484,
     'explain': 485,
     'crap': 486,
     'particularly': 487,
     'dog': 488,
     'provide': 489,
     'hours': 490,
     'cannot': 491,
     'allow': 492,
     'across': 493,
     'none': 494,
     'ago': 495,
     'serious': 496,
     'note': 497,
     'shock': 498,
     'exactly': 499,
     'draw': 500,
     'reality': 501,
     'parent': 502,
     'seriously': 503,
     'possible': 504,
     'plan': 505,
     'stick': 506,
     'documentary': 507,
     'relationship': 508,
     'sad': 509,
     'avoid': 510,
     'song': 511,
     'gun': 512,
     'sing': 513,
     'important': 514,
     'team': 515,
     'usually': 516,
     'talent': 517,
     'alone': 518,
     'english': 519,
     'check': 520,
     'female': 521,
     'whose': 522,
     'middle': 523,
     'compare': 524,
     'focus': 525,
     'convince': 526,
     'produce': 527,
     'jack': 528,
     'ridiculous': 529,
     'country': 530,
     'pull': 531,
     'class': 532,
     'cover': 533,
     'steal': 534,
     'cinematography': 535,
     'scary': 536,
     'happy': 537,
     'major': 538,
     'silly': 539,
     'somewhat': 540,
     'four': 541,
     'mostly': 542,
     'strange': 543,
     'single': 544,
     'basically': 545,
     'huge': 546,
     'usual': 547,
     'apparently': 548,
     'opinion': 549,
     'message': 550,
     'marry': 551,
     'attention': 552,
     'shots': 553,
     'pass': 554,
     'escape': 555,
     'novel': 556,
     'form': 557,
     'beyond': 558,
     'hop': 559,
     'clich': 560,
     'subject': 561,
     'prove': 562,
     'cheap': 563,
     'win': 564,
     'non': 565,
     'detail': 566,
     'thriller': 567,
     'wear': 568,
     'imagine': 569,
     'rock': 570,
     'sequel': 571,
     'fill': 572,
     'modern': 573,
     'ones': 574,
     'thank': 575,
     'clearly': 576,
     'due': 577,
     'problems': 578,
     'alien': 579,
     'straight': 580,
     'french': 581,
     'future': 582,
     'discover': 583,
     'charm': 584,
     'season': 585,
     'british': 586,
     'upon': 587,
     'bear': 588,
     'clear': 589,
     'remain': 590,
     'events': 591,
     'fast': 592,
     'drug': 593,
     'train': 594,
     'develop': 595,
     'air': 596,
     'fit': 597,
     'space': 598,
     'local': 599,
     'date': 600,
     'earth': 601,
     'comic': 602,
     'doubt': 603,
     'television': 604,
     'image': 605,
     'king': 606,
     'near': 607,
     'battle': 608,
     'entertainment': 609,
     'ten': 610,
     'fire': 611,
     'attack': 612,
     'hate': 613,
     'dialog': 614,
     'mark': 615,
     'george': 616,
     'box': 617,
     'easily': 618,
     'predictable': 619,
     'chase': 620,
     'general': 621,
     'musical': 622,
     'within': 623,
     'remind': 624,
     'five': 625,
     'similar': 626,
     'easy': 627,
     'send': 628,
     'romantic': 629,
     'bunch': 630,
     'storyline': 631,
     'enjoyable': 632,
     'carry': 633,
     'confuse': 634,
     'bill': 635,
     'ways': 636,
     'e': 637,
     'typical': 638,
     'certain': 639,
     'episodes': 640,
     'copy': 641,
     'sorry': 642,
     'whether': 643,
     'issue': 644,
     'dull': 645,
     'capture': 646,
     'mystery': 647,
     'agree': 648,
     'crime': 649,
     'songs': 650,
     'elements': 651,
     'th': 652,
     'among': 653,
     'monster': 654,
     'water': 655,
     'soundtrack': 656,
     'tale': 657,
     'list': 658,
     'suspense': 659,
     'mess': 660,
     'notice': 661,
     'york': 662,
     'mix': 663,
     'suck': 664,
     'gay': 665,
     'minute': 666,
     'effort': 667,
     'america': 668,
     'viewers': 669,
     'cartoon': 670,
     'trouble': 671,
     'richard': 672,
     'blow': 673,
     'beat': 674,
     'hide': 675,
     'sister': 676,
     'red': 677,
     'suffer': 678,
     'theater': 679,
     'eat': 680,
     'tom': 681,
     'choose': 682,
     'peter': 683,
     'doctor': 684,
     'finish': 685,
     'continue': 686,
     'okay': 687,
     'free': 688,
     'reveal': 689,
     'nearly': 690,
     'premise': 691,
     'fly': 692,
     'excite': 693,
     'period': 694,
     'romance': 695,
     'remake': 696,
     'realistic': 697,
     'de': 698,
     'soldier': 699,
     'dr': 700,
     'lady': 701,
     'party': 702,
     'truth': 703,
     'fantastic': 704,
     'somehow': 705,
     'famous': 706,
     'average': 707,
     'contain': 708,
     'drink': 709,
     'believable': 710,
     'material': 711,
     'fi': 712,
     'third': 713,
     'paul': 714,
     'sci': 715,
     'appreciate': 716,
     'cry': 717,
     'background': 718,
     'crew': 719,
     'describe': 720,
     'lee': 721,
     'deep': 722,
     'whatever': 723,
     'hat': 724,
     'greatest': 725,
     'oscar': 726,
     'actual': 727,
     'poorly': 728,
     'weak': 729,
     'indeed': 730,
     'eventually': 731,
     'lame': 732,
     'forward': 733,
     'admit': 734,
     'treat': 735,
     'society': 736,
     'adventure': 737,
     'baby': 738,
     'western': 739,
     'atmosphere': 740,
     'animation': 741,
     'bother': 742,
     'possibly': 743,
     'match': 744,
     'fear': 745,
     'lie': 746,
     'situation': 747,
     'project': 748,
     'otherwise': 749,
     'difficult': 750,
     'sexual': 751,
     'hot': 752,
     'control': 753,
     'imdb': 754,
     'plus': 755,
     'particular': 756,
     'boys': 757,
     'stage': 758,
     'male': 759,
     'flaw': 760,
     'appeal': 761,
     'shame': 762,
     'suggest': 763,
     'footage': 764,
     'mistake': 765,
     'accent': 766,
     'screenplay': 767,
     'warn': 768,
     'struggle': 769,
     'personal': 770,
     'cheesy': 771,
     'costume': 772,
     'towards': 773,
     'memorable': 774,
     'rise': 775,
     'previous': 776,
     'land': 777,
     'earlier': 778,
     'island': 779,
     'street': 780,
     'joe': 781,
     'unless': 782,
     'perfectly': 783,
     'emotional': 784,
     'powerful': 785,
     'business': 786,
     'respect': 787,
     'serve': 788,
     'spirit': 789,
     'total': 790,
     'tear': 791,
     'quickly': 792,
     'front': 793,
     'fantasy': 794,
     'writers': 795,
     'badly': 796,
     'nature': 797,
     'crazy': 798,
     'color': 799,
     'older': 800,
     'store': 801,
     'masterpiece': 802,
     'dramatic': 803,
     'girlfriend': 804,
     'superb': 805,
     'term': 806,
     'era': 807,
     'award': 808,
     'company': 809,
     'rich': 810,
     'rip': 811,
     'scream': 812,
     'master': 813,
     'various': 814,
     'weird': 815,
     'post': 816,
     'unique': 817,
     'inside': 818,
     'answer': 819,
     'brothers': 820,
     'jump': 821,
     'japanese': 822,
     'hole': 823,
     'c': 824,
     'amuse': 825,
     'dress': 826,
     'development': 827,
     'beauty': 828,
     'promise': 829,
     'incredibly': 830,
     'race': 831,
     'concern': 832,
     'plenty': 833,
     'amount': 834,
     'william': 835,
     'fairly': 836,
     'cat': 837,
     'track': 838,
     'disturb': 839,
     'ghost': 840,
     'brain': 841,
     'kick': 842,
     'directors': 843,
     'culture': 844,
     'apart': 845,
     'outside': 846,
     'secret': 847,
     'sell': 848,
     'inspire': 849,
     'dumb': 850,
     'rate': 851,
     'travel': 852,
     'sleep': 853,
     'roll': 854,
     'political': 855,
     'villain': 856,
     'blue': 857,
     'channel': 858,
     'disney': 859,
     'creepy': 860,
     'gang': 861,
     'success': 862,
     'ideas': 863,
     'clever': 864,
     'unlike': 865,
     'scar': 866,
     'cute': 867,
     'burn': 868,
     'share': 869,
     'plain': 870,
     'public': 871,
     'claim': 872,
     'search': 873,
     'step': 874,
     'record': 875,
     'design': 876,
     'nudity': 877,
     'accept': 878,
     'german': 879,
     'filmmakers': 880,
     'talented': 881,
     'large': 882,
     'potential': 883,
     'office': 884,
     'italian': 885,
     'camp': 886,
     'destroy': 887,
     'ride': 888,
     'hardly': 889,
     'perform': 890,
     'cross': 891,
     'grant': 892,
     'exist': 893,
     'former': 894,
     'odd': 895,
     'strike': 896,
     'co': 897,
     'zombie': 898,
     'fake': 899,
     'recently': 900,
     'band': 901,
     'introduce': 902,
     'intrigue': 903,
     'ring': 904,
     'spoilers': 905,
     'pure': 906,
     'violent': 907,
     'van': 908,
     'reach': 909,
     'neither': 910,
     'flat': 911,
     'slightly': 912,
     'pop': 913,
     'park': 914,
     'ship': 915,
     'la': 916,
     'cold': 917,
     'members': 918,
     'science': 919,
     'survive': 920,
     'relate': 921,
     'familiar': 922,
     'count': 923,
     'drag': 924,
     'scott': 925,
     'hang': 926,
     'language': 927,
     'judge': 928,
     'social': 929,
     'listen': 930,
     'popular': 931,
     'prison': 932,
     'choice': 933,
     'harry': 934,
     'suddenly': 935,
     'spot': 936,
     'entirely': 937,
     'u': 938,
     'drop': 939,
     'sweet': 940,
     'sadly': 941,
     'approach': 942,
     'sam': 943,
     'century': 944,
     'purpose': 945,
     'ruin': 946,
     'concept': 947,
     'fiction': 948,
     'tone': 949,
     'intelligent': 950,
     'common': 951,
     'taste': 952,
     'college': 953,
     'fashion': 954,
     'hair': 955,
     'raise': 956,
     'wind': 957,
     'producers': 958,
     'portrayal': 959,
     'visual': 960,
     'tension': 961,
     'effective': 962,
     'law': 963,
     'suspect': 964,
     'pointless': 965,
     'clothe': 966,
     'receive': 967,
     'incredible': 968,
     'ultimately': 969,
     'situations': 970,
     'trash': 971,
     'engage': 972,
     'suit': 973,
     'revenge': 974,
     'haunt': 975,
     'bar': 976,
     'longer': 977,
     'key': 978,
     'trip': 979,
     'depth': 980,
     'handle': 981,
     'younger': 982,
     'normal': 983,
     'alive': 984,
     'cult': 985,
     'torture': 986,
     'successful': 987,
     'edge': 988,
     'yeah': 989,
     'f': 990,
     'rule': 991,
     'paint': 992,
     'honest': 993,
     'pathetic': 994,
     'studio': 995,
     'basic': 996,
     'visit': 997,
     'solid': 998,
     'impress': 999,
     'bond': 1000,
     ...}




```python
embedding_matrix[3]
```




    array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])




```python
from tensorflow.keras.layers import Dense, LSTM, Bidirectional, Embedding, Dropout
from tensorflow.keras.models import Sequential
from tensorflow.keras.callbacks import ModelCheckpoint
```


```python
model = Sequential([
    Embedding(VOCAB_SIZE, EMBEDDING_DIM, input_length=MAX_LENGTH, 
              weights=[embedding_matrix], 
              trainable=False,
             ), 
    Bidirectional(LSTM(128, return_sequences=True)), 
    Bidirectional(LSTM(128)), 
    Dropout(0.25), 
    Dense(32, activation='relu'), 
    Dense(1, activation='sigmoid')
])
```


```python
model.summary()
```

    Model: "sequential"
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    embedding (Embedding)        (None, 150, 300)          37893000  
    _________________________________________________________________
    bidirectional (Bidirectional (None, 150, 256)          439296    
    _________________________________________________________________
    bidirectional_1 (Bidirection (None, 256)               394240    
    _________________________________________________________________
    dropout (Dropout)            (None, 256)               0         
    _________________________________________________________________
    dense (Dense)                (None, 32)                8224      
    _________________________________________________________________
    dense_1 (Dense)              (None, 1)                 33        
    =================================================================
    Total params: 38,734,793
    Trainable params: 841,793
    Non-trainable params: 37,893,000
    _________________________________________________________________
    


```python
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])
```


```python
checkpoint_path = 'tmp/checkpoint.ckpt'
checkpoint = ModelCheckpoint(filepath=checkpoint_path, 
                             save_best_only=True, 
                             save_weights_only=True, 
                             monitor='val_loss', 
                             verbose=1,
                            )
```


```python
model.fit(x_train, y_train, 
          validation_data=(x_valid, y_valid), 
          batch_size=128, 
          epochs=20, 
          callbacks=[checkpoint]
         )
```

    Epoch 1/20
    176/176 [==============================] - 493s 3s/step - loss: 0.6932 - acc: 0.4965 - val_loss: 0.6931 - val_acc: 0.5000
    
    Epoch 00001: val_loss improved from inf to 0.69315, saving model to tmp\checkpoint.ckpt
    Epoch 2/20
    176/176 [==============================] - 535s 3s/step - loss: 0.6932 - acc: 0.4957 - val_loss: 0.6931 - val_acc: 0.5000
    
    Epoch 00002: val_loss improved from 0.69315 to 0.69315, saving model to tmp\checkpoint.ckpt
    Epoch 3/20
    176/176 [==============================] - 568s 3s/step - loss: 0.6932 - acc: 0.4951 - val_loss: 0.6931 - val_acc: 0.5000
    
    Epoch 00003: val_loss did not improve from 0.69315
    Epoch 4/20
    176/176 [==============================] - 523s 3s/step - loss: 0.6932 - acc: 0.4948 - val_loss: 0.6931 - val_acc: 0.5000
    
    Epoch 00004: val_loss did not improve from 0.69315
    Epoch 5/20
    176/176 [==============================] - 568s 3s/step - loss: 0.6932 - acc: 0.4917 - val_loss: 0.6931 - val_acc: 0.5000
    
    Epoch 00005: val_loss did not improve from 0.69315
    Epoch 6/20
    176/176 [==============================] - 560s 3s/step - loss: 0.6932 - acc: 0.4998 - val_loss: 0.6931 - val_acc: 0.5000
    
    Epoch 00006: val_loss did not improve from 0.69315
    Epoch 7/20
    176/176 [==============================] - 633s 4s/step - loss: 0.6932 - acc: 0.4982 - val_loss: 0.6932 - val_acc: 0.5000
    
    Epoch 00007: val_loss did not improve from 0.69315
    Epoch 8/20
    176/176 [==============================] - 622s 4s/step - loss: 0.6932 - acc: 0.4960 - val_loss: 0.6931 - val_acc: 0.5000
    
    Epoch 00008: val_loss did not improve from 0.69315
    Epoch 9/20
    176/176 [==============================] - 606s 3s/step - loss: 0.6932 - acc: 0.4990 - val_loss: 0.6931 - val_acc: 0.5000
    
    Epoch 00009: val_loss did not improve from 0.69315
    Epoch 10/20
    176/176 [==============================] - 818s 5s/step - loss: 0.6932 - acc: 0.4956 - val_loss: 0.6931 - val_acc: 0.5000
    
    Epoch 00010: val_loss did not improve from 0.69315
    Epoch 11/20
    176/176 [==============================] - 914s 5s/step - loss: 0.6932 - acc: 0.4910 - val_loss: 0.6931 - val_acc: 0.5000
    
    Epoch 00011: val_loss did not improve from 0.69315
    Epoch 12/20
    176/176 [==============================] - 901s 5s/step - loss: 0.6932 - acc: 0.4979 - val_loss: 0.6931 - val_acc: 0.5000
    
    Epoch 00012: val_loss did not improve from 0.69315
    Epoch 13/20
    176/176 [==============================] - 856s 5s/step - loss: 0.6932 - acc: 0.4981 - val_loss: 0.6931 - val_acc: 0.5000
    
    Epoch 00013: val_loss did not improve from 0.69315
    Epoch 14/20
    176/176 [==============================] - 895s 5s/step - loss: 0.6932 - acc: 0.4950 - val_loss: 0.6931 - val_acc: 0.5000
    
    Epoch 00014: val_loss did not improve from 0.69315
    Epoch 15/20
    176/176 [==============================] - 941s 5s/step - loss: 0.6932 - acc: 0.5003 - val_loss: 0.6931 - val_acc: 0.5000
    
    Epoch 00015: val_loss did not improve from 0.69315
    Epoch 16/20
    176/176 [==============================] - 886s 5s/step - loss: 0.6932 - acc: 0.4965 - val_loss: 0.6931 - val_acc: 0.5000
    
    Epoch 00016: val_loss did not improve from 0.69315
    Epoch 17/20
    176/176 [==============================] - 674s 4s/step - loss: 0.6932 - acc: 0.4997 - val_loss: 0.6931 - val_acc: 0.5000
    
    Epoch 00017: val_loss did not improve from 0.69315
    Epoch 18/20
    176/176 [==============================] - 682s 4s/step - loss: 0.6932 - acc: 0.4987 - val_loss: 0.6931 - val_acc: 0.5000
    
    Epoch 00018: val_loss did not improve from 0.69315
    Epoch 19/20
    176/176 [==============================] - 561s 3s/step - loss: 0.6932 - acc: 0.4993 - val_loss: 0.6931 - val_acc: 0.5000
    
    Epoch 00019: val_loss did not improve from 0.69315
    Epoch 20/20
    176/176 [==============================] - 3324s 19s/step - loss: 0.6932 - acc: 0.4988 - val_loss: 0.6931 - val_acc: 0.5000
    
    Epoch 00020: val_loss did not improve from 0.69315
    




    <keras.callbacks.History at 0x23cd7b75bb0>




```python
model.load_weights(checkpoint_path)
```




    <tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x23cc40d2af0>




```python
model.evaluate(x_valid, y_valid)

```

    79/79 [==============================] - 10s 126ms/step - loss: 0.1946 - acc: 0.9300
    




    [0.19461557269096375, 0.9300000071525574]




```python
prediction = model.predict(test_padded)
```


```python
prediction
```




    array([[0.9427937 ],
           [0.06540772],
           [0.21975702],
           ...,
           [0.07580322],
           [0.91583395],
           [0.07085294]], dtype=float32)




```python
prediction[prediction >= 0.5] = 1
prediction[prediction < 0.5] = 0
```


```python
prediction
```




    array([[1.],
           [0.],
           [0.],
           ...,
           [0.],
           [1.],
           [0.]], dtype=float32)




```python

```


```python

```


```python

```
